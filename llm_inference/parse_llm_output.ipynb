{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3b0e6b5-455e-4a6e-b61e-48afe6cf0ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "gcap_data = \"/oak/stanford/groups/maggiori/GCAP/data/\"\n",
    "ai_geo1 = \"/oak/stanford/groups/maggiori/GCAP/data/ai_geo1/\"\n",
    "model = \"llama33_70b\"\n",
    "years = ['2025']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a48e03aa-1091-4c5d-adaf-ff6af9caf893",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_list = ['tariffs_any', \n",
    "             'export_controls_any',\n",
    "             'sanctions_any',\n",
    "             'boycotts_any',\n",
    "             'investment_screening_any',\n",
    "             'geo_subsidies_any',\n",
    "             'geoeconomic_any',\n",
    "             'summary',\n",
    "             'parse_error']\n",
    "\n",
    "def safe_json_loads(output_str):\n",
    "    try:\n",
    "        result = {}\n",
    "        parse_error = False\n",
    "        # Remove the header/footer tags\n",
    "        output_str = output_str.replace(\"<|start_header_id|>assistant<|end_header_id|>\", \"\")\n",
    "        output_str = output_str.replace(\"```json\", \"<JSON>\")\n",
    "        output_str = output_str.replace(\"```\", \"</JSON>\")\n",
    "        # Extract JSON portion between <JSON> and </JSON>\n",
    "        json_start = output_str.find(\"<JSON>\") + len(\"<JSON>\")\n",
    "        json_end = output_str.find(\"</JSON>\")\n",
    "        if json_start == -1 or json_end == -1:\n",
    "            parse_error = True\n",
    "        else:\n",
    "            json_str = output_str[json_start:json_end]\n",
    "            result = json.loads(json_str)\n",
    "        \n",
    "        summary_start = output_str.find(\"<SUMMARY>\") + len(\"<SUMMARY>\") \n",
    "        summary_end = output_str.find(\"</SUMMARY>\")\n",
    "        if summary_start == -1 or summary_end == -1:\n",
    "            parse_error = True\n",
    "        else:\n",
    "            result['summary'] = output_str[summary_start:summary_end].strip()\n",
    "        \n",
    "        result['parse_error'] = \"1\" if parse_error else \"0\"\n",
    "        \n",
    "        return result\n",
    "    except:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a9a6a05-3e5b-4146-93cf-a512244d1b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parse errors: 0 for year 2025\n"
     ]
    }
   ],
   "source": [
    "for year in years:\n",
    "    df = pd.read_parquet(ai_geo1 + f\"/temp/transcripts/broad_analysis_{model}_{year}_workshop_sample.parquet\")\n",
    "    parsed_outputs = [safe_json_loads(output) for output in df['llm_output']]\n",
    "\n",
    "    all_dicts = []\n",
    "    for parsed_output in parsed_outputs:\n",
    "        output_dict = {}\n",
    "        for col in cols_list:\n",
    "            output_dict[col] = str(parsed_output.get(col)) if isinstance(parsed_output, dict) else None\n",
    "        if parsed_output is None:\n",
    "            output_dict['parse_error'] = \"1\"\n",
    "        all_dicts.append(output_dict)\n",
    "\n",
    "    for col in all_dicts[0].keys():\n",
    "        df[col] = [d[col] for d in all_dicts]\n",
    "\n",
    "    num_of_parse_errors = df[df['parse_error'] == \"1\"].shape[0]\n",
    "\n",
    "    print(f\"number of parse errors: {num_of_parse_errors} for year {year}\")\n",
    "\n",
    "    df.to_parquet(ai_geo1 + f\"temp/transcripts/broad_analysis_{model}_{year}_workshop_sample_parsed.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5abc0622-7101-413f-af32-9ace64be0afe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<JSON>\n",
      "{\n",
      "  \"tariffs_any\": 1,\n",
      "  \"sanctions_any\": 0,\n",
      "  \"export_controls_any\": 0,\n",
      "  \"boycotts_any\": 0,\n",
      "  \"investment_screening_any\": 0,\n",
      "  \"geo_subsidies_any\": 0,\n",
      "  \"geoeconomic_any\": 1\n",
      "}\n",
      "</JSON>\n",
      "\n",
      "<SUMMARY>\n",
      "The company discusses the potential impact of tariffs on their business, mentioning that they have manufacturing facilities in the U.S., Europe, and Asia, which gives them flexibility to address any tariff situation. They also mention that they are well-situated to handle tariffs due to their global manufacturing presence. However, they do not provide any specific details on how tariffs have affected their business in the past or how they plan to mitigate any potential negative impacts in the future.\n",
      "\n",
      "The company does not discuss sanctions, export controls, boycotts, investment screening, or geoeconomic subsidies in the context of their business. However, they do mention the potential for geoeconomic pressure, particularly with regards to the new administration's focus on border security and the potential for increased funding for border security initiatives. The company believes that their technology and products are well-positioned to support these initiatives, and they expect to see growth in their business as a result.\n",
      "\n",
      "Overall, the company appears to be well-positioned to handle any potential geoeconomic pressures, particularly with regards to tariffs and border security initiatives. However, they do not provide any specific details on how they plan to address these issues or what potential risks they may pose to their business.\n",
      "</SUMMARY>\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[0].llm_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06a6eaa9-d7bc-491b-8715-1a61956f6c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025: {\"tariffs_any\": 44, \"export_controls_any\": 1, \"sanctions_any\": 0, \"boycotts_any\": 0, \"investment_screening_any\": 0, \"geo_subsidies_any\": 2, \"geoeconomic_any\": 45}\n"
     ]
    }
   ],
   "source": [
    "flags = ['tariffs_any', \n",
    "         'export_controls_any',\n",
    "         'sanctions_any',\n",
    "         'boycotts_any',\n",
    "         'investment_screening_any',\n",
    "         'geo_subsidies_any',\n",
    "         'geoeconomic_any']\n",
    "\n",
    "\n",
    "for year in years:\n",
    "    df_new = pd.read_parquet(ai_geo1 + f\"temp/transcripts/broad_analysis_{model}_{year}_workshop_sample_parsed.parquet\")\n",
    "    stat = {}\n",
    "    for flag in flags:\n",
    "        stat[flag] = len(df_new[df_new[flag] == \"1\"])\n",
    "    print(f\"{year}: {json.dumps(stat)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83938aa1-1b6d-49b9-bea4-fd6fd69c96f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
